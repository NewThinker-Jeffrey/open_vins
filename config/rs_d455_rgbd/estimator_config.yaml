%YAML:1.0 # need to specify the file type at the top!

verbosity: "INFO" # ALL, DEBUG, INFO, WARNING, ERROR, SILENT

async_img_process: true # whethre to run feature tracking and state update in separate threads.

use_fej: true # if first-estimate Jacobians should be used (enable for good consistency)
use_imuavg: true # if using discrete integration, if we should average sequential IMU measurements to "smooth" it
use_rk4int: true # if rk4 integration should be used (overrides imu averaging)

use_stereo: true # if we have more than 1 camera, if we should try to track stereo constraints between pairs
max_cameras: 1 # how many cameras we have 1 = mono, 2 = stereo, >2 = binocular (all mono tracking)

propagate_with_stereo_feature: false
grivaty_update_after_propagate_with_stereo_feature: true
propagation_feature_n_select: 20
propagation_feature_n_max_adopt: 1
propagation_feature_skip_latest_used: true
propagation_feature_n_con_thr: 4
propagation_feature_n_con_thr2: 10
propagation_feature_con_trans_diff_thr: 0.01  # metre
propagation_feature_bearing_sigma: 0.0025  # rad
propagation_feature_force_psuedo_stationary: false
propagation_feature_psuedo_stationary_sigma: 0.7  # metre

disable_visual_update: false     # for testing propagation

feat_viz_cur_only_highlighted: true
feat_viz_prev_only_highlighted: true

use_rgbd: true
virtual_baseline_for_rgbd: 0.095
depth_unit_for_rgbd: 0.001

rgbd_mapping: true
rgbd_mapping_pixel_downsample: 3
rgbd_mapping_pixel_start_row:  0  # 160
rgbd_mapping_pixel_end_row:  -1
rgbd_mapping_pixel_start_col:  0
rgbd_mapping_pixel_end_col:  -1
rgbd_mapping_resolution: 0.01
rgbd_mapping_max_depth: 5.0
rgbd_mapping_max_height: 0.8
rgbd_mapping_min_height: -1.5
rgbd_mapping_max_voxels: 2000000
rgbd_mapping_max_dispaly_voxels: 500000

use_semantic_masking: false
semantic_masking_model_path: "/slam/seg_model"
semantic_masking_profiler_path: "/tmp/mmseg_profile.bin"
semantic_masking_labels_to_mask: [15]  # 15 stands for 'person' in VOC12 dataset.
semantic_masking_dilate_kernel_size: 5

calib_cam_extrinsics: true # if the transform between camera and IMU should be optimized R_ItoC, p_CinI
calib_cam_intrinsics: true # if camera intrinsics should be optimized (focal, center, distortion)
calib_cam_timeoffset: true # if timeoffset between camera and IMU should be optimized

vio_manager_high_frequency_log: false
choose_new_landmark_by_disparity: true
enable_early_landmark: true

max_clones: 11 # how many clones in the sliding window
max_slam: 50 # number of features in our state vector
max_slam_in_update: 25 # update can be split into sequential updates of batches, how many in a batch
max_msckf_in_update: 40 # how many MSCKF features to use in the update
dt_slam_delay: 1 # delay before initializing (helps with stability from bad initialization...)

gravity_mag: 9.81 # magnitude of gravity in this location

feat_rep_msckf: "GLOBAL_3D"
feat_rep_slam: "ANCHORED_MSCKF_INVERSE_DEPTH"
feat_rep_aruco: "ANCHORED_MSCKF_INVERSE_DEPTH"


# zero velocity update parameters we can use
# we support either IMU-based or disparity detection.
try_zupt: true
zupt_chi2_multipler: 1.0 # set to 0 for only disp-based
zupt_max_velocity: 0.1
zupt_noise_multiplier: 10
zupt_max_disparity: 0 # set to 0 for only imu-based
zupt_only_at_beginning: false

# ==================================================================
# ==================================================================

init_window_time: 2.0 # how many seconds to collect initialization information
init_imu_thresh: 1.5 # threshold for variance of the accelerometer to detect a "jerk" in motion
init_max_disparity: 10.0 # max disparity to consider the platform stationary (dependent on resolution)
init_max_features: 75 # how many features to track during initialization (saves on computation)

init_dyn_use: false # if dynamic initialization should be used
init_dyn_mle_opt_calib: false # if we should optimize calibration during intialization (not recommended)
init_dyn_mle_max_iter: 50 # how many iterations the MLE refinement should use (zero to skip the MLE)
init_dyn_mle_max_time: 0.05 # how many seconds the MLE should be completed in
init_dyn_mle_max_threads: 6 # how many threads the MLE should use
init_dyn_num_pose: 6 # number of poses to use within our window time (evenly spaced)
init_dyn_min_deg: 10.0 # orientation change needed to try to init

init_dyn_inflation_ori: 10 # what to inflate the recovered q_GtoI covariance by
init_dyn_inflation_vel: 100 # what to inflate the recovered v_IinG covariance by
init_dyn_inflation_bg: 10 # what to inflate the recovered bias_g covariance by
init_dyn_inflation_ba: 100 # what to inflate the recovered bias_a covariance by
init_dyn_min_rec_cond: 1e-12 # reciprocal condition number thresh for info inversion

init_dyn_bias_g: [ 0.0, 0.0, 0.0 ] # initial gyroscope bias guess
init_dyn_bias_a: [ 0.0, 0.0, 0.0 ] # initial accelerometer bias guess

# ==================================================================
# ==================================================================

record_timing_information: true # if we want to record timing information of the method
record_timing_filepath: "/tmp/traj_timing.txt" # https://docs.openvins.com/eval-timing.html#eval-ov-timing-flame

# if we want to save the simulation state and its diagional covariance
# use this with rosrun ov_eval error_simulation
save_total_state: false
filepath_est: "/tmp/ov_estimate.txt"
filepath_std: "/tmp/ov_estimate_std.txt"
filepath_gt: "/tmp/ov_groundtruth.txt"

# ==================================================================
# ==================================================================

# our front-end feature tracking parameters
# we have a KLT and descriptor based (KLT is better implemented...)
use_klt: true # if true we will use KLT, otherwise use a ORB descriptor + robust matching
num_pts: 200 # number of points (per camera) we will extract and try to track
fast_threshold: 20 # threshold for fast extraction (warning: lower threshs can be expensive)
grid_x: 5 # extraction sub-grid count for horizontal direction (uniform tracking)
grid_y: 5 # extraction sub-grid count for vertical direction (uniform tracking)
min_px_dist: 10 # distance between features (features near each other provide less information)
knn_ratio: 0.70 # descriptor knn threshold for the top two descriptor matches

track_frequency: 11.0 # frequency we will perform feature tracking at (in frames per second / hertz)
    # NOTE: In RGBD mode, the actual tracking freq might also depend on the frequency of depth images.

downsample_cameras: false # will downsample image in half if true
num_opencv_threads: 4 # -1: auto, 0-1: serial, >1: number of threads
histogram_method: "HISTOGRAM" # NONE, HISTOGRAM, CLAHE

klt_left_major_stereo: true
klt_strict_stereo: false
klt_force_fundamental: true
feattrack_high_frequency_log: false
feattrack_predict_keypoints: true

# aruco tag tracker for the system
# DICT_6X6_1000 from https://chev.me/arucogen/
use_aruco: false
num_aruco: 1024
downsize_aruco: true

# ==================================================================
# ==================================================================

# camera noises and chi-squared threshold multipliers
up_msckf_sigma_px: 2
up_msckf_chi2_multipler: 1
up_msckf_absolute_residual_thr: -1.0
# up_msckf_absolute_residual_thr: 3.0

up_slam_sigma_px: 2
up_slam_chi2_multipler: 1
up_slam_absolute_residual_thr: -1.0
# up_slam_absolute_residual_thr: 3.0

up_aruco_sigma_px: 2
up_aruco_chi2_multipler: 1
up_aruco_absolute_residual_thr: -1.0
# up_aruco_absolute_residual_thr: 3.0

# masks for our images
use_mask: false

# imu and camera spacial-temporal
# imu config should also have the correct noise values
relative_config_imu: "kalibr_imu_chain.yaml"
# relative_config_imucam: "kalibr_imucam_chain.yaml"
relative_config_imucam: "kalibr_imucam_chain_848width.yaml"


#### testing parameters

# early_landmark_disparity_thr: 0.017  # 1Â°
imu_acc_filter_param: 0.0   # no filter used

early_landmark_disparity_thr: 0.02
# imu_acc_filter_param: 20.0  # acc filter window: 20 (only used by propagator)


